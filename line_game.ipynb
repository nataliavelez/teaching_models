{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreating figures from line game in Shafto 2014 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup: \n",
    "\n",
    "- 6 possible hypotheses $h_1$ through $h_6$ in hypothesis space \n",
    "- Uniform prior over hypotheses $P(h_{i}) = \\frac{1}{6}$\n",
    "- 12 data $d_1$ through $d_{12}$, where teacher reveals two segments that are labeled to be either inside the hypothesis or outside the hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "#sns.set()\n",
    "sns.set_style('white')\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create hypotheses array\n",
    "h = np.array([\n",
    "    [1, 0, 0], \n",
    "    [1, 1, 0], \n",
    "    [1, 1, 1], \n",
    "    [0, 1, 0], \n",
    "    [0, 1, 1], \n",
    "    [0, 0, 1]\n",
    "])\n",
    "\n",
    "# create data array\n",
    "d = np.array([\n",
    "    [1, 1, np.nan],\n",
    "    [1, 0, np.nan], \n",
    "    [0, 1, np.nan], \n",
    "    [0, 0, np.nan], \n",
    "    [1, np.nan, 1], \n",
    "    [1, np.nan, 0], \n",
    "    [0, np.nan, 1],\n",
    "    [0, np.nan, 0],\n",
    "    [np.nan, 1, 1],\n",
    "    [np.nan, 1, 0], \n",
    "    [np.nan, 0, 1],\n",
    "    [np.nan, 0, 0]\n",
    "])\n",
    "\n",
    "# create mask for hypothesis array for NaN values\n",
    "d_mask = np.ma.masked_invalid(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding probabilities for iteration 0: $P(d|h)$, random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_possible = {}  # Set up dict of possible d for each h\n",
    "\n",
    "rows = ['d_1', 'd_2', 'd_3', 'd_4', \n",
    "        'd_5', 'd_6', 'd_7', 'd_8', \n",
    "        'd_9', 'd_10', 'd_11', 'd_12']\n",
    "columns = ['h_1', 'h_2', 'h_3', 'h_4', 'h_5', 'h_6']\n",
    "df_0 = pd.DataFrame(index=rows, columns=columns).fillna(0)\n",
    "\n",
    "# Loop over all combinations of h and d and fill dataframe with possible values\n",
    "for row_h in range(h.shape[0]): \n",
    "    for row_d in range(d.shape[0]): \n",
    "        if np.array_equal(d[row_d][~d_mask.mask[row_d]], h[row_h][~d_mask.mask[row_d]]):\n",
    "            d_possible.setdefault(row_h+1, []).append(row_d+1)\n",
    "            df_0.iloc[row_d, row_h] = 1  # uniform distribution of data given each hypothesis\n",
    "            \n",
    "# Turn values into probabilities; each column sums up to 1\n",
    "df_0 = df_0.div(df_0.sum(axis=0), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View combinations: Keys are indices for d and values are indices for h\n",
    "d_possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration 0 probabilities\n",
    "df_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4.8,7))\n",
    "sns.heatmap(df_0, annot=True, linewidths=0.25)\n",
    "plt.title('Iteration 0: $P_{teacher} (d|h)$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilities for iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(index=rows, columns=columns).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea: \n",
    "\n",
    "$$ P_{learner}(h|d) = \\frac{P_{teacher}(d|h) P(h)}{\\sum_{h'} {P_{teacher}(d|h') P(h')}} $$\n",
    "\n",
    "(prior probabilities of hypothesis are all $\\frac{1}{6}$, so it cancels out)\n",
    "\n",
    "$$ P_{teacher}(d|h) = \\frac{P_{learner}(h|d) P(d)}{\\sum_{d'} {P_{learner}(h|d')P(d')}} $$\n",
    "\n",
    "(priors of d are the same for each iteration, too? should be one over number of possible data corresponding to each hypothesis) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(h|d) for learner \n",
    "df_1 = df_0.div(df_0.sum(axis=1), axis=0)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New P(d|h) for teacher\n",
    "df_1 = df_1.div(df_1.sum(axis=0), axis=1)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5.5,8))\n",
    "sns.heatmap(df_1, annot=True, linewidths=0.25)\n",
    "plt.title('Iteration 1: $P_{teacher} (d|h)$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterations 2 and beyond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_teacher_probabilities(n, df_0):\n",
    "    '''\n",
    "    given number of iterations n and P(d|h) matrix for iteration 0, find P(d|h) matrix after iteration n \n",
    "    '''\n",
    "    n_iter = n\n",
    "    df = df_0\n",
    "\n",
    "    for n in range(n_iter): \n",
    "        df = df.div(df.sum(axis=1), axis=0)  # P(h|d)\n",
    "        df = df.div(df.sum(axis=0), axis=1)  # P(d|h)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = find_teacher_probabilities(2, df_0)\n",
    "\n",
    "plt.figure(figsize=(5.5,8))\n",
    "sns.heatmap(df_2, annot=True, linewidths=0.25)\n",
    "plt.title('Iteration 2: $P_{teacher} (d|h)$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check: $d_6$, iteration 2\n",
    "$$ P_{teacher} (d_6 | h_2) = \\frac{.33/.53}{(.33/.58) + (.33/.53) + (.33/.58)} \\approx .354 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration 500\n",
    "\n",
    "df_500 = find_teacher_probabilities(500, df_0)\n",
    "\n",
    "plt.figure(figsize=(5.5,8))\n",
    "sns.heatmap(df_500, annot=True, linewidths=0.25)\n",
    "plt.title('Iteration 500: $P_{teacher} (d|h)$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting a few distributions over iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_dict = {\n",
    "    'd6h1': [df_0.loc['d_6', 'h_1']], \n",
    "    'd2h1': [df_0.loc['d_2', 'h_1']], \n",
    "    'd1h2': [df_0.loc['d_1', 'h_2']], \n",
    "    'd6h2': [df_0.loc['d_6', 'h_2']],\n",
    "    'd1h3': [df_0.loc['d_1', 'h_3']],\n",
    "    'd5h3': [df_0.loc['d_5', 'h_3']]\n",
    "             }\n",
    "\n",
    "for n in range(1,250):\n",
    "    df = find_teacher_probabilities(n, df_0)\n",
    "    probs_dict['d6h1'].append(df.loc['d_6', 'h_1'])\n",
    "    probs_dict['d2h1'].append(df.loc['d_2', 'h_1'])\n",
    "    probs_dict['d1h2'].append(df.loc['d_1', 'h_2'])\n",
    "    probs_dict['d6h2'].append(df.loc['d_6', 'h_2'])\n",
    "    probs_dict['d1h3'].append(df.loc['d_1', 'h_3'])\n",
    "    probs_dict['d5h3'].append(df.loc['d_5', 'h_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_probs = pd.DataFrame(probs_dict)\n",
    "df_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_probs.iloc[:50, :].plot(xlabel='Iteration', ylabel='$P(d|h)$')\n",
    "plt.title('Example probabilities over first 50 iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all model predictions together into one matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtx_0 = df_0.to_numpy()\n",
    "mtx_1 = df_1.to_numpy()\n",
    "mtx_500 = df_500.to_numpy()\n",
    "\n",
    "posterior_mtx = np.stack([mtx_0, mtx_1, mtx_500],axis=-1)\n",
    "print(posterior_mtx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate $H(d|h)$:\n",
    "\n",
    "$$\n",
    "H(X) = -\\sum_{i=1}^{n}\\mathrm{P}(x_i)\\mathrm{log}_b\\mathrm{P}(x_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute entropy\n",
    "entropy_mtx = stats.entropy(posterior_mtx)\n",
    "\n",
    "# Assemble into a tidy datframe\n",
    "entropy_df = pd.DataFrame(entropy_mtx, \n",
    "                          index=['h_%i' % (i+1) for i in range(6)],\n",
    "                          columns=['0', '1', '500'])\n",
    "\n",
    "entropy_df.index.name = 'hypothesis' # Hypothesis column\n",
    "entropy_df = entropy_df.reset_index()\n",
    "\n",
    "entropy_df = pd.melt(entropy_df, id_vars=['hypothesis'], value_vars=['0','1','500'],\n",
    "                     var_name='iterations', value_name='entropy')\n",
    "\n",
    "entropy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.relplot(data=entropy_df, x='iterations', y='entropy', col='hypothesis', kind='line')\n",
    "ax.set(xlabel='Iterations', ylabel='Entropy: $H(d|h)$')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
